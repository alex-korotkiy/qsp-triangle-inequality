# Repository purpose and structure

This is a repository for a small research project that aims to optimize Sugiyama-Borgwardt outlier detection algorithm: https://papers.nips.cc/paper_files/paper/2013/file/d296c101daa88a51f6ca8cfc1ac79b50-Paper.pdf by using triangle inequality for metrics and developing an index which allows skipping some of the distance calculations.

## Projects folder

has .NET 5.0 (C#) program as Visual Studio solution (*Project/AlgorithmsOptimization/AlgorithmsOptimization.sln*), which does algorithms comparison. Could be run from the command line:

*AlgorithhmsOptimization.exe OutputPath [DatasetName]*

When launched, runs algorithms and writes comparison results to the OutputPath in CSV format. DatasetName is an optional parameter. If specified, compare algorithms only on specified dataset. If not – process all datasets.
Also has a unit tests project (*Project/AlgorithmsOptimizationTests*). The main purpose of unit tests is to check that optimized and base algorithms have the same output.

All datasets are included in the project’s data folder (*Project/AlgorithmsOptimization/Data*) in CSV format. They are included in the repository as a zip archive due to GitHub's 100MB file size limit. Important - unpack csv files into the same folder before opening Visual Studio solution. 

Note: for accurate performance results, compile the project in Release mode.

## Output folder. 

Contains comparison results for each dataset in CSV format

## Formatted folder 

A shortened version of comparison results (also in CSV format). Generated from the full version in Output folder by Python script *format_table.py*. Tables from this folder contain results presented in the next section

## Charts folder

Graphs with comparison of performance results, generated by Pyplot script *build_chart.py* from Output folder

## Scripts folder

Contains two utility Python scripts that take algorithm comparison results in the Output folder and produce user-friendly files with the most important metrics: 

1. *format_table.py* – generates a presentable view with comparison results in csv format for each dataset

2. *build_chart.py* – builds a graphical representation of such kind of table for each dataset



